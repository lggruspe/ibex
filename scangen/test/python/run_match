#!/usr/bin/env python3
import argparse
import os.path
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import output.scanners as scanners

def test_longest_match():
    token, lexeme = scanners.match_longest(*(scanners.SCANNER.values()))
    print(token)
    print(lexeme)

def test_single_match(scanner):
    _, lexeme = scanner().match()
    print(lexeme)

def test_tokenizer():
    while True:
        token, lexeme = scanners.match_longest(*(scanners.SCANNER.values()))
        if token == scanners.Token.EMPTY:
            break
        print(token, lexeme)

def main():
    def get_args():
        description = "Run python scangen example."
        parser = argparse.ArgumentParser(description=description)
        subparsers = parser.add_subparsers(
            dest="subcommand",
            help="sub-command help")
        parser_single = subparsers.add_parser(
            "single",
            help="match input to a single scanner")
        parser_single.add_argument(
            "-s",
            dest="scanner",
            help="name of scanner ({})".format('|'.join(scanners.SCANNER.keys())))
        parser_longest = subparsers.add_parser(
            "longest",
            help="find longest match")
        parser_tokenizer = subparsers.add_parser(
            "tokenizer",
            help="tokenize input")
        return parser.parse_args()

    args = get_args()
    if args.subcommand == "single":
        test_single_match(scanners.SCANNER[args.scanner])
    elif args.subcommand == "longest":
        test_longest_match()
    elif args.subcommand == "tokenizer":
        test_tokenizer()

if __name__ == "__main__":
    try:
        main()
    except KeyError:
        print("Invalid argument")
    except IndexError:
        print("Missing arguments")
